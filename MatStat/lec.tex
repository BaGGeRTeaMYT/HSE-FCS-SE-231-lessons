\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage[margin=0.25in]{geometry}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\usepackage{nicefrac}
\graphicspath{../Images}
\usepackage{tikz}
\usepackage{cancel}

\usepackage{fontspec}
\setmainfont{Times New Roman}

\newcommand{\sion}{\sum\limits_{i = 1}^{n}}
\newcommand{\dev}{\mathcal{D}}
\newcommand{\cov}{\operatorname{cov}}

\title{Математическая статистика.}
\author{Андрей Тищенко \href{https://t.me/AndrewTGk}{@AndrewTGk}}
\date{2024/2025}

\begin{document}
\maketitle
\begin{center}
    Лекция 10 января
\end{center}
\section*{Преамбула}
\textit{Статистика}. Мнения о появлении этого слова:
\begin{enumerate}
    \item Статистиками в Германии назывались люди, собирающие данные о населении и передающие их государству.
    \item В определённый день в Венеции народ выстраивался для выплаты налогов (строго фиксированных, в зависимости от рода действий). Государство собирало данные обо всём населении. Это происходило до появления статистиков в Германии, поэтому мы будем считать, что статистика пошла из Венеции.
\end{enumerate}
\textit{Задача статистики} --- по результатам наблюдений построить вероятностную модель наблюдаемой случайной величины.
\section*{Основные определения}
\subsection*{Определение}
\underline{Однородной выборкой объёма $n$} называется случайный вектор $X = (X_1,\dots,\ X_n)$, компоненты которого являются независимыми и одинаково распределёнными. Элементы вектора $X$ называются \underline{элементами}\\\underline{выборки}. 
\subsection*{Определение}
Если элементы выборки имеют распределение $F_{\xi}(x)$, то говорят, что выборка \underline{соответствует распределению} $F_{\xi}(x)$ или \underline{порождена случайной величиной} $\xi$ с распределением $F_{\xi}(x)$. 
\subsection*{Определение}
Детерминированный вектор $x = (x_1,\dots,\ x_n)$, компоненты которого $x_i$ являются реализациями соответствующих случайных величин $X_i\ (i = \overline{1,\ n})$, называется \underline{реализацией выборки}.
\subsection*{Уточнение}
Если $X$ --- однородная выборка объёма $n$, то его реализацией будет вектор $x$, каждый элемент $x_i$ которого является значением соответствующей ему случайной величины (элемента выборки) $X_i$. 
\subsection*{Определение}
\underline{Выборочным пространством} называется множество всех возможных реализаций выборки\\
\[X = (X_1,\dots,\ X_n)\]
\subsection*{Пример}
У вектора $X = (X_1,\dots,\ X_{10})$ каждый элемент $X_i$ которой порождён случайной величиной $\xi\sim U(0,\ 1)$, выборочным пространством является $\mathbb{R}^{10}$ (так как $X_i$ может принять любое значение на $\mathbb{R}$)
\subsection*{Определение}
Обозначим $x_{(i)}$ --- $i$-ый по возрастанию элемент, тогда будет справедливо:
\[x_{(1)} \leq x_{(2)} \leq \dots \leq x_{(n)}\]
Обозначим $X_{(k)}$ случайную величину, реализация которой при каждой реализации $x$ выборки $X$ принимает значение $x_{(k)}$. Тогда последовательность $X_{(1)},\dots,\ X_{(n)}$ называется \underline{вариационным рядом выборки}.
\subsection*{Определение}
Случайная величина $X_{(k)}$ называется \underline{$k$-ой порядковой статистикой выборки}.
\subsection*{Определение}
Случайные величины $X_{(1)},\ X_{(n)}$ называются \underline{эстремальными порядковыми статистиками}.
\subsection*{Определение}
Порядковая статистика $X_{(\lceil n\cdot p \rceil)}$ называется \underline{выборочной квантилью уровня $p$}, где $p\in [0,\ 1]$
\subsection*{Определение}
Пусть каждый элемент выборки $X$ объёма n имеет распределение $F_{\xi}(x)$. \underline{Эмпирической функцией}\\ \underline{распределения} такой выборки называется
\[\hat{F}_n(x) = \frac{1}{n} \sum_{k = 1}^{n} I(X_k\leq x)\]
$I$ --- индикаторная функция. $I = \begin{cases}
    1,\ \text{если аргумент верен}\\
    0,\ \text{иначе}
\end{cases}$\\
Пусть $x_1,\dots,\ x_n$ --- реализация выборки $X_1,\dots,\ X_n$\\
\[\begin{tikzpicture}[scale=2, >=latex]
    \draw[->, >=latex] (0, -1) -- (0, 1) node(0)[anchor = east]{$\hat{F}_n(x)$};
    \draw (-2, -0.05) node(1)[anchor=north]{$x_1$} -- (-2, 0.05);
    \draw (-1, -0.05) node(2)[anchor=north]{$x_2$}-- (-1, 0.05);
    \draw (0.07, -0.05) node(3)[anchor=north east]{$x_3$}-- (0.07, -0.05);
    \draw (1, -0.05) node(4)[anchor=north]{$x_4$}-- (1, 0.05);
    \draw (2, -0.05) node(5)[anchor=north]{$x_5$}-- (2, 0.05);
    \draw[->] (-3, 0) -- (-2, 0);
    \draw[->] (-2, 0.2) -- (-1, 0.2);
    \draw[dashed] (-2, 0) -- (-2, 0.2);
    \draw[->] (-1, 0.45) -- (0, 0.45);
    \draw[dashed] (-1, 0) -- (-1, 0.45);
    \draw[->] (0, 0.6) -- (1, 0.6);
    \draw[dashed] (1, 0) -- (1, 0.85);
    \draw[->] (1, 0.85) -- (2, 0.85);
    \draw[dashed] (2, 0) -- (2, 1);
    \draw[->] (2, 1) -- (3, 1);
    \draw[->] (-3, 0) -- (3, 0) node(2)[anchor = south]{$x$};
\end{tikzpicture}\]
\begin{center}
    Свойства $\hat{F}_n(x)$
\end{center}
\begin{enumerate}
    \item $\displaystyle\forall x\in\mathbb{R}\quad E\hat{F}_n(x) = E\left(\frac{1}{n} \sum_{k = 1}^{n} I(X_k \leq x)\right) = \frac{1}{n} \sum_{k = 1}^{n} EI(X_k \leq x) = P(X_1 \leq x) = F_{\xi}(x)$
    \item По усиленному закону больших чисел (УЗБЧ)
    \[\forall x\in \mathbb{R}\quad \hat{F}_n(x) = \frac{1}{n} \sum_{k = 1}^{n} I(X_k \leq x) \xrightarrow[n\to\infty]{\text{п. н.}} EI(X_k \leq x) = F_{\xi}(x)\]
\end{enumerate}
\subsection*{Гистограмма}
Разбить $\mathbb{R}$ на $(m + 2)$ непересекающихся интервала. Рассматриваются $x_{(1)},\dots,\ x_{(m)}$
\[\begin{tabular}{|c|c|c|}
    \hline
    Название & Обозначение & Формула\\
    \hline
    $\begin{aligned}&\text{Количество}\\&\text{интервалов}\end{aligned}$ & $m$ & ---\\
    \hline
    $\begin{aligned}&\text{Размах}\\&\text{выборки}\end{aligned}$ & $r$ & $r = x_{(m)} - x_{(1)}$\\
    \hline
    $\begin{aligned}&\text{Ширина}\\&\text{интервала}\end{aligned}$ & $\Delta$ & $\Delta = \frac{r}{m}$\\
    \hline
    $\begin{aligned}&\text{Количество}\\&\text{попаданий на}\\&\text{$i$-ый интервал}\end{aligned}$ & $\nu_i$ & ---\\
    \hline
    $\begin{aligned}&\text{Частота}\\&\text{попаданий на}\\&\text{$i$-ый интервал}\end{aligned}$ & $h_i$ & $h_i = \frac{\nu_i}{\Delta}$\\
    \hline
\end{tabular}\quad
\begin{tikzpicture}[scale=2, >=latex]
    \draw[->] (-2, 0) -- (2, 0) node(2)[anchor = south]{$x$};
    \draw (-1.5, -0.1) node[anchor=north](4){$x_{(1)}$} -- (-1.5, 0.1) node(3){};
    \draw (1.5, -0.1) node[anchor=north](6){$x_{(m)}$} -- (1.5, 0.1) node(5){};
    \draw[<->] (-1.5, -0.08) -- node[anchor=north](10){$r$} (1.5, -0.08);
    \draw (0.75, -0.05) -- (0.75, 0.05) node(6){};
    \draw[<->] (-0.75, 0.08) -- node[anchor=south](11){$\Delta$} (0, 0.08);
    \draw (0, -0.05) -- (0, 0.05) node(8){};
    \draw (-0.75, -0.05) -- (-0.75, 0.05) node(9){};
    \draw (-1.5, 0) rectangle (-0.75, 0.5);
    \draw[->] (0.375, 0) -- node(0)[anchor = west]{$h_i$} (0.375, 0.75);
    \draw (-0.75, 0) rectangle (-0.0, 0.8);
    \draw (-0.0, 0) rectangle (0.75, 0.75);
    \draw (0.75, 0) rectangle (1.5, 0.2);
\end{tikzpicture}\]
\begin{center}
    Лекция 17 января
\end{center}
\subsection*{Определение}
Пусть $X_1,\dots,\ X_n \sim F(x,\ \theta)$. \underline{$k$-ым начальным выборочным моментом} называется \[\hat{\mu}_k = \frac{1}{n} \sum_{i = 1}^{n} x_i^k,\ k \in \mathbb{N}\]
\underline{Выборочным средним} называется:
\[\hat{\mu}_1 = \overline{x} = \frac{1}{n} \sum_{i = 1}^{n} x_i\]
\subsection*{Определение}
\underline{$k$-ым центральным выборочным моментом} называется 
\[\hat{\nu}_k = \frac{1}{n} \sum_{i = 1}^{n} (x_i - \overline{x})^k,\ k = 2,\ 3,\dots\]
\[\hat{\nu}_2 = S^2 = \frac{1}{n} \sum_{i = 1}^{n} (x_i - \overline{x})^2 \text{ называется выборочной дисперсией}\]
Пусть $(x_1,\ y_1),\dots,\ (x_n,\ y_n)$ соответствует распределению $F(x,\ y,\ \theta)$
\subsection*{Определение}
\underline{Выборочной ковариацией} называется
\[\hat{K}_{xy} = \frac{1}{n}\sum_{i = 1}^{n} (x_i - \overline{x}) (y_i - \overline{y})\]
\subsection*{Определение}
\underline{Выборочным коэффициентом корреляции} называется 
\[\hat{\rho}_{xy} = \frac{\hat{K}_{xy}}{\sqrt{S_x^2 S_y^2}}\]
\begin{center}
    Свойства выборочных моментов
\end{center}
\begin{enumerate}
    \item $E\hat{\mu}_k = E\left( \frac{1}{n} \sum_{i = 1}^{n} X_i^k \right) = \frac{1}{n} \sum_{i = 1}^{n} E X_i^k = EX_1^k = \mu_k$
    \item $E\overline{X} = m_x$
    \item $\mathcal{D} \hat{\mu}_k = \mathcal{D} \left( \frac{1}{n} \sum_{i = 1}^{n} x_i^k \right) = \frac{1}{n^2} \sum_{i = 1}^{n} \mathcal{D} X_i^k = \frac{1}{n} \mathcal{D} X_i^k = \frac{1}{n} \left( EX_1^{2k} - (EX_1^{K})^2 \right) = \frac{1}{n}(\mu_{2k} - \mu_k^2)$
    \item $\mathcal{D}\overline{x} = \frac{\sigma^2_{x_1}}{n}$
    \item По УЗБЧ
    \[\hat{\mu}_k = \frac{1}{n} \sum_{i = 1}^{n} x_i^k \xrightarrow[n\to \infty]{\text{п. н.}} E\hat{\mu}_k = \mu_k\]
    \[\hat{\nu}_k \xrightarrow[n\to \infty]{\text{п. н.}} \nu_k\]
    \item По ЦПТ
    \[\frac{\hat{\mu}_k - \mu_k}{\sqrt{\frac{\mu_{2k} - \mu_k^2}{n} }}\xrightarrow[d]{n\to\infty}U,\ U\sim N(0,\ 1)\]
    \[\frac{\sqrt{n}(\overline{x} - m_{x_1})}{\sigma} \xrightarrow[n\to\infty]{d} U\]
    \item $ES^2 = E\left( \frac{1}{n} \sum_{i = 1}^{n}(x_i - \overline{x})^2 \right) = \frac{n - 1}{n} \sigma^2$
    \item $E \hat{K}_{xy} = \frac{n - 1}{n} \cov(x,\ y)$
\end{enumerate}
\subsection*{Определение}
Оценкой $\hat{\theta}$ параметра $\theta$, называется функция:
\[\hat{\theta} = T(x_1,\dots,\ x_n),\ \text{не зависящая от $\theta$}\]
Например, отвратительная оценка среднего роста людей в аудитории.
\[\hat{m} = \frac{2x_2 + 5x_5 + 10x_{10}}{3}\]
\subsection*{Определение}
Оценка $\hat{\theta}$ называется \underline{несмещённой}, если $E\hat{\theta} = \theta$ для любых возможных значений этого параметра.
\subsection*{Определение}
Оценка $\hat{\theta}(x_1,\dots,\ x_n)$ называется \underline{асимптотически несмещённой оценкой} $\theta$, если
\[\lim_{n\to\infty} E\hat{\theta}(x_1,\dots,\ x_n) = \theta\]
\[\lim_{n\to\infty} ES^2 = \lim_{n\to\infty} \frac{n - 1}{n}\sigma^2 = \sigma^2\]
\subsection*{Определение}
\underline{Несмещённой выборочной} (или исправленной) \underline{выборочной дисперсией} называется
\[\tilde{S}^2 = \frac{1}{n - 1} \sum_{i = 1}^{n} (x_i - \overline{x})^2\]
Оценки
\[\begin{aligned}
    \hat{m}_1 &= \frac{x_1 + x_2 + x_3}{3}\\
    \hat{m}_2 &= \frac{\sum_{i = 1}^{10} x_i}{10}\\
    \hat{m}_3 &= \overline{x} = \frac{\sion x_i}{n}\\  
\end{aligned}\]
Являются несмещёнными.
\subsection*{Определение}
Оценка $\hat{\theta}(x_1,\dots,\ x_n)$ называется:\\
\underline{Состоятельной оценкой} $\theta$, если
\[\hat{\theta} (x_1,\dots,\ x_n) \xrightarrow[n\to\infty]{p} \theta\]
\underline{Сильно состоятельной оценкой}, если
\[\hat{\theta} (x_1,\dots,\ x_n) \xrightarrow[n\to\infty]{\text{п. н.}} \theta\]
\subsection*{Определение}
Пусть $\hat{\theta}$ --- несмещённая оценка параметра $\theta$. Если $\dev\hat{\theta} \leq \dev \theta^*$, где $\theta^*$ --- любая несмещённая оценка параметра $\theta$. Тогда $\hat{\theta}$ называется \underline{эффективной оценкой параметра} $\theta$.
\begin{center}
    $R$-эффективные оценки
\end{center}
Рассматриваем выборку $X_1,\ldots,\ X_n \sim f(x,\ \theta),\ \theta\in \Theta \subseteq \mathbb{R}^1$. Назовём модель $(S,\ f(x,\ \theta))$ \underline{регулярной}, если она удовлетворяет следующим условиям:
\begin{enumerate}
    \item $\forall x\in S\quad \text{функция } f(x,\ \theta) = f(x_1,\dots,\ x_n,\ \theta) > 0$ и дифференцируема по $\theta$.
    \item $\begin{cases} \displaystyle\frac{\delta}{\delta \theta} \int\limits_S f(x,\ \theta)\, dx = \int\limits_S \frac{\delta}{\delta \theta} f(x,\ \theta)\, dx\\
        \displaystyle \frac{\delta}{\delta \theta} \int\limits_S T(x)f(x,\ \theta)\, dx = \int\limits_S \frac{\delta}{\delta \theta} T(x) f(x,\ \theta)\, dx \end{cases}$
\end{enumerate}
Пусть $\hat{\theta} = T(x) = T(x_1,\dots,\ x_n)$ --- несмещённая оценка параметра $\theta$:
\[\int\limits_S \frac{\delta}{\delta \theta} f(x,\ \theta)\, dx = \frac{\delta}{\delta \theta} \int\limits_S f(x,\ \theta)\, dx = \frac{\delta}{\delta \theta} 1 = 0\]
\[\int\limits_S \frac{\delta}{\delta \theta} T(x) f(x,\ \theta)\, dx =  \frac{\delta}{\delta \theta} \int\limits_S T(x) f(x,\ \theta) \, dx = \frac{\delta}{\delta\theta} ET(x) = \frac{\delta}{\delta \theta}\theta = 1\]
\subsection*{Определение}
\underline{Информацией Фишера} о параметре $\theta$, содержащейся в выборке $X_1,\dots,\ X_n$ называется величина
\[I_n(\theta) = E\left( \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} \right)^2 = \int\limits_S\left( \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} \right)^2 f(x,\ \theta)\, dx\]
\subsection*{Неравенство Рао-Крамера}
Если $S,\ f(x,\ \theta)$ --- регулярная модель и $\hat{\theta}$ --- несмещённая оценка $\theta$, то 
\[\dev (\hat{\theta}) \geq \frac{1}{I_n(\theta)}\]
\textbf{Доказательство}\\
Выпишем некоторые равенства (пригодятся в доказательстве):
\[\int\limits_S \frac{\delta}{\delta \theta} f(x,\ \theta)\, dx = \int\limits_S \frac{\delta f(x,\ \theta)}{\delta \theta} \frac{f(x,\ \theta)}{f(x,\ \theta)}\, dx \overset{*}{=} \int\limits_S \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx = 0\]
Пояснение $\overset{*}{=}$. Логарифм --- сложная функция. По правилу дифференцирования сложной функции:
\[\frac{\delta \ln f(x,\ \theta)}{\delta \theta} = \frac{1}{f(x,\ \theta)} \cdot \frac{\delta f(x,\ \theta)}{\delta \theta}\]
\[\int\limits_S \frac{\delta}{\delta \theta} T(x) f(x,\ \theta)\, dx = \int\limits_S T(x) \frac{\delta}{\delta \theta} f(x,\ \theta) \frac{f(x,\ \theta)}{f(x,\ \theta)}\, dx = \int\limits_S T(x) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx = 1\]
Чуть преобразуем последнее полученное равенство:
\[\int\limits_S T(x) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx = \int\limits_S T(x) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx - \theta\underset{=0}{\underbrace{\int\limits_S \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx}} = \]
\[= \int\limits_S \big( T(x) - \theta \big) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx = 1 \Rightarrow 1 = 1^2 = \left( \int\limits_S \big( T(x) - \theta \big) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx \right)^2 \]
Далее нам понадобится неравенство Коши-Буняковского, которое выглядит так:
\[\left( \int \varphi_1(x)\varphi_2(x)\, dx \right)^2 \leq \int \varphi_1^2(x)\, dx\int \varphi_2^2(x)\, dx\]
Подгоним полученное равенство $\left(f(x,\ \theta) > 0 \Rightarrow f(x,\ \theta) = \sqrt{f(x,\ \theta)}^2\right)$:
\[\left( \int\limits_S \big( T(x) - \theta \big) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx \right)^2 = \left( \int\limits_S \underset{\varphi_1(x)}{\underbrace{\big( T(x) - \theta \big) \sqrt{f(x,\ \theta)}}}\cdot\underset{\varphi_2(x)}{\underbrace{\frac{\delta \ln f(x,\ \theta)}{\delta \theta} \sqrt{f(x,\ \theta)}}}\, dx \right)^2 = 1\]
И применим неравенство Коши-Буняковского:
\[1 = \left( \int\limits_S \underset{\varphi_1(x)}{\underbrace{\big( T(x) - \theta \big) \sqrt{f(x,\ \theta)}}}\cdot\underset{\varphi_2(x)}{\underbrace{\frac{\delta \ln f(x,\ \theta)}{\delta \theta} \sqrt{f(x,\ \theta)}}}\, dx \right)^2 \leq\]
\[\leq \int\limits_S \left( (T(x) - \theta)\sqrt{f(x,\ \theta)} \right)^2 \, dx \cdot \int\limits_S \left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \sqrt{f(x,\ \theta)} \right)^2 \, dx =\]
\[= \underset{=\dev\hat{\theta}}{\underbrace{\int\limits_S \big( T(x) - \theta \big)^2 f(x,\ \theta)\, dx}} \cdot \underset{=I_n(\theta)}{\underbrace{\int\limits_S\left( \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} \right)^2 f(x,\ \theta)\, dx}}\]
Получаем:
\[1 \leq \dev (\theta) \cdot I_n(\theta)\Rightarrow \dev (\theta) \geq \frac{1}{I_n(\theta)}\]
\subsection*{Определение}
Оценка $\hat{\theta}$ называется \underline{$R$-эффективной}, если $E\hat{\theta} = \theta$ и $\dev \hat{\theta} = \frac{1}{I_n(\theta)}$
\begin{center}
    Лекция 24 января
\end{center}
\subsection*{Замечание 1}
$I_n(\theta) = \dev \left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \right)$
\subsection*{Замечание 2}
$I_n(\theta) = nI_1(\theta)$\\
$\displaystyle f(x,\ \theta) = f(x_1,\dots,\ x_n,\ \theta) = \prod_{i = 1}^{n} f(x_i,\ \theta)\\
E\left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \right)^2 = E \left( \sion \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta} \right)^2 = \sum_{i \neq j} E \left( \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta} \cdot \frac{\delta \ln f(x_j,\ \theta)}{\delta \theta} \right) + nE\left( \frac{\delta \ln f(x_1, \theta)}{\delta \theta} \right)^2 =\\
= \sum_{i \neq j} \left( \underset{=0}{\underbrace{E \left( \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta}\right)}} \cdot \underset{=0}{\underbrace{E\left( \frac{\delta \ln f(x_j,\ \theta)}{\delta \theta} \right)}}\right) + nE\left( \frac{\delta \ln f(x_1, \theta)}{\delta \theta} \right)^2 = nE\left( \frac{\delta \ln f(x_1, \theta)}{\delta \theta} \right)^2 = nI_1(\theta)$
\subsection*{Замечание 3}
Пример: $X_1,\dots,\ X_n \sim N(\theta,\ \sigma^2)$\\
Рассмотрим оценку $\hat{\theta} = \overline{X}$, её дисперсия $\mathcal{D}\overline{X} = \frac{\sigma^2}{n}$. Посчитаем информацию Фишера:\\
$I_1(\theta) = E\left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \right)^2 = E\left( \frac{\delta}{\delta \theta} \ln\left( \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x - \theta)^2}{2\sigma^2}}\right) \right)^2 = E\left( \frac{\delta}{\delta \theta} \ln\left( \frac{1}{\sqrt{2\pi} \sigma} - \frac{(x - \theta)^2}{2\sigma^2} \right) \right)^2 = E\left( \frac{x - \theta}{\sigma^2} \right)^2 = \\
=\frac{1}{\sigma^4} E(x - \theta)^2 = \frac{\sigma^2}{\sigma^4} = \frac{1}{\sigma^2}\Rightarrow I_n(\theta) = \frac{n}{\sigma^2}$\\
Знаем, что $\mathcal{D}\hat{\theta} \geq \frac{1}{nI_1(\theta)} = \frac{\sigma^2}{n} = \mathcal{D}(\overline{X})\Rightarrow$ оценка $\hat{\theta} = \overline{X}$ является R-эффективной.\\
Критерий эффективности $X_1,\dots,\ X_n \sim F_{\xi}(x,\ \theta),\ \theta \in \Theta \subset \mathbb{R}^1$ выполнены условия регулярности, то есть
\[ \int T(x)\frac{\delta f(x,\ \theta)}{\delta \theta}\, dx = \frac{\delta}{\delta \theta} \int T(x) f(x,\ \theta)\, dx = E\hat{\theta}\]

\subsection*{Определение}
Функцией вклада выборки $X_1,\dots,\ X_n$ называется
\[U(x,\ \theta) = \sion \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta}\]
Пусть $0 < U(x, \theta) < \infty$.\\
$\hat{\theta} = T(x_1,\dots,\ x_n)$ --- R-эффективная оценка $\theta \Leftrightarrow \hat{\theta} - \theta = a(\theta) U(x,\ \theta)$, где $a(\theta) = \mathcal{D}\hat{\theta}$\\
\textit{Доказательство} $\Rightarrow$:\\
Пусть $\hat{\theta} - \theta = a(\theta) U(x,\ \theta) \Rightarrow \hat{\theta}$ --- R-эффективная оценка $\theta$.\\
Посчитаем математическое ожидание частей равенства:
\[E(\hat{\theta} - \theta) = a(\theta) EU(x,\ \theta) = a(\theta) \int \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta) dx = 0\]
Посчитаем дисперсию частей:
\[\dev (\hat{\theta} - \theta) = a^2(\theta) \dev U(x,\ \theta) = \underset{=(\dev(\hat{\theta}))^2}{\underbrace{a^2(\theta)}} I_n(\theta)\Rightarrow \dev(\hat{\theta}) = (\dev(\hat{\theta}))^2 I_n(\theta)\Rightarrow 1 = \dev(\theta) I_n(\theta)\]
Значит оценка является R-эффективной.\\
\textit{Доказательство} $\Leftarrow$:\\
Пусть $\hat{\theta}$ --- R-эффективная оценка $\Rightarrow \hat{\theta} - \theta = a(\theta) U(x,\ \theta)$. Хотим доказать, что $\rho(\hat{\theta},\ U(x,\ \theta)) = 1$.\\
Для подсчёта корреляции нужно посчитать ковариацию:
\[\cov (\hat{\theta},\ U(x,\ \theta)) = E(\hat{\theta} - \theta) U(x,\ \theta) = E\hat{\theta} U(x,\ \theta) - \theta \underset{=0}{\underbrace{EU(x,\ \theta)}} =\]
\[= \int\limits_S T(x)U(x,\ \theta) f(x,\ \theta)\, dx = \int\limits_S T(x) \frac{\delta \ln f(x,\ \theta)}{\delta \theta}f(x,\ \theta)\, dx = 1\]
Так как $\hat{\theta}$ --- R-эффективная оценка, то $\dev \hat{\theta} = \frac{1}{I_n(\theta)}$. Знаем, что $\dev U(x,\ \theta) = I_n(\theta)$, тогда:
\[\rho(\hat{\theta},\ U(x,\ \theta)) = \frac{\cov (\hat{\theta},\ U(,\ \theta))}{\sqrt{\dev \hat{\theta} \dev U(x,\ \theta)}} = \frac{1}{\sqrt{\frac{I_n(\theta)}{I_n(\theta)}}} = 1\Rightarrow\]
\[\Rightarrow \hat{\theta} = c_1 + c_2U(x,\ \theta)\]
$E\hat{\theta} = c_1 + Ec_2 U(x,\ \theta) = c_1 + 0 = \theta$, так как оценка эффективная\\
$\dev \hat{\theta} = c_2^2 I_n(\theta) = \frac{1}{I_n(\theta)}\Rightarrow c_2^2 = \frac{1}{I_n^2}\Rightarrow c_2 = \frac{1}{I_n} = \dev\hat{\theta} = a(\theta)$.\\
Итак, $\hat{\theta} = \theta + a(\theta) U(x,\ \theta)\Rightarrow \hat{\theta} - \theta = U(x,\ \theta)$.
\subsection*{Метод моментов}
$X_1,\dots,\ X_n\sim F_{\xi}(x,\ \theta),\ \theta \in \Theta\subset R^k$
\[\exists \mu_j < \infty,\ j = \overline{1,\ k}\quad \underset{=\mu_j(\theta)}{\underbrace{\mu_j}} = E\xi^j = \int\limits_{-\infty}^{+\infty} x^j f(x,\ \theta)\, dx = 1\]
Тогда можно получить систему уравнений:
\begin{equation}
    \begin{cases}
        \hat{\mu}_1 = \mu_1(\theta)\\
        \vdots\\
        \hat{\mu}_k = \mu_k(\theta)
    \end{cases}
\end{equation}
Если система уравнений $(1)$ однозначно разрешима относительно $\theta_1,\dots,\ \theta_k$, то решения $\hat{\theta_1},\dots,\ \hat{\theta_k}$ называется равной $\theta_1,\dots,\ \theta_k$ по методу моментов.
\subsubsection*{Пример}
$X_1,\dots,\ X_n \sim N(\theta_1,\ \theta_2^2),\ \theta = (\theta_1,\ \theta_2^2)$, тогда:
\[\begin{cases}
    \hat{\mu}_1 = \frac{1}{n} \sion x_i = \theta_1\Rightarrow \hat{\theta_1} = \overline{X}\\
    \hat{\mu}_2 = \frac{1}{n} \sion x_i^2 = \theta_2^2 + \theta_1^2,\ \big(E\xi^2 = \dev \xi + (E\xi)^2\big)\Rightarrow \hat{\theta}_2^2 = \frac{1}{n}\sion  x_i^2 = \overline{X}^2
\end{cases}\]
\subsection*{Метод максимального правдоподобия (ММП)}
\subsubsection*{Определение}
Функцией правдоподобия для $X_1,\dots,\ X_n$, порождённых случайной величиной $\xi$, называется функция 
\[L(x_1,\dots,\ x_n,\ \theta) = \begin{cases}
    \prod\limits_{i = 1}^{n} f(x_i,\ \theta),\ \text{если $\xi$ --- непрерывная случайная величина}\\
    \prod\limits_{i = 1}^{n} P(\xi = x_i,\ \theta),\ \text{если $\xi$ --- дискретная случайная величина}
\end{cases}\]
\subsubsection*{Определение}
Реализацией оценки максимального правдоподобия (ОМП) называется значение $\hat{\theta} \in \Theta$, такое что:
\[\hat{\theta} = \operatorname{argmax} L(x_1,\dots,\ x_n,\ \theta),\ \text{где }\theta \in \Theta\]
Для нахождения точки максимума нужно взять частные производные по всем составляющим $\theta$ от функции правдоподобия. Однако считать производную произведения нам впадлу, поэтому мы введём следующую вещь:
\subsubsection*{Определение}
Функция $\ln L(x_1,\dots,\ x_n,\ \theta)$ называется логарифмической функцией правдоподобия.\\
Итак, получаем систему уравнений:
\[\begin{cases}
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{\delta \theta_1} = 0\\
    \vdots\\
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{\delta \theta_k} = 0
\end{cases}\]
Логарифм монотонный, поэтому его argmax совпадёт с argmax функции $L(x_1,\dots,\ x_n,\ \theta)$ (НАУКА!).
\subsubsection*{Пример}
Для Гауссовской величины $N(\theta_1,\ \theta_2^2)$:
\[L(x_1,\dots,\ x_n,\ \theta) = \prod\limits_{i = 1}^{n} \frac{1}{\sqrt{2\pi}\sigma^2} e^{-\frac{(x - \theta_1)^2}{2\theta_2^2}} = \left( \frac{1}{\sqrt{2\pi}} \right)^n \left( \frac{1}{\theta_2} \right)^n e^{-\frac{(x - \theta_1)^2}{2\theta_2^2}}\]
Логарифмируем:
\[\ln L(x_1,\dots,\ x_n,\ \theta) = \ln \left( \frac{1}{\sqrt{2\pi}} \right)^n - n\ln \theta_2 - \frac{\sion (x_i - \theta_1)^2}{2\theta_2^2}\]
Возьмём частные производные:
\[\begin{cases}
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{ \delta \theta_1} = \frac{\sion (x_i - \hat{\theta}_1)}{\hat{\theta}_2^2}\\
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{\delta \theta_2} = -\frac{n}{\hat{\theta}_2} + \frac{\sion (x_i - \hat{\theta}_1)^2}{\hat{\theta_2}^3}
\end{cases}\]
Посчитаем $\theta_1,\ \theta_2$:
\[\begin{cases}
    \sion (x_i - \hat{\theta}_1) = 0 \Rightarrow \hat{\theta}_1 = \frac{1}{n} \sion x_i = \overline{X}\\
    -n\hat{\theta}_2^2 + \sion (x_i - \overline{x})^2 = 0 \Rightarrow \hat{\theta}_2^2 = \frac{1}{n} \sion (x_i - \overline{x})^2
\end{cases}\]
\begin{center}
    \bf Лекция 31 января.
\end{center}
\subsection*{Робастные оценки}
От слова robust.\\
\subsection*{Определение}
Пусть оценка $\hat{\theta}_n$ построена по выборке $X_1,\dots,\ X_n$. Затем добавлено наблюдение $x$ и построена оценка $\hat{\theta}_{n + 1}$, тогда \underline{кривой чувствительности}, изучающей влияние наблюдения $x$ на оценку $\hat{\theta}$ называется функция:
\[S C_n (x) = \frac{\hat{\theta}_{n + 1} - \hat{\theta}_n}{\frac{1}{n + 1}} = (n + 1)\left( \hat{\theta}_{n + 1} - \hat{\theta}_n \right)\]
\subsection*{Определение}
Оценка $\hat{\theta}$ называется $B$-робастной, если $SC_n(x)$ ограничена.
\subsubsection*{Пример}
Пусть $\hat{\theta} = \overline{X}$
\[SC_n(x) = (n + 1)\left( \frac{1}{n + 1} \left( \sion (x_i) + x \right) - \frac{1}{n} \sion x_i \right) = \sion x_i + x - \left( \sion x_i + \frac{1}{n} \sion x_i \right) = x - \overline{X}\]
Это линейная функция от $x$, то есть кривая чувствительности неограничена.\\
Пусть $\hat{\theta} = \hat{\mu}$ (выборочная медиана)
\[\hat{\mu} = \begin{cases}
    X_{(k + 1)},\ n = 2k + 1\\
    \frac{X_{(k)} + X_{(k + 1)}}{2},\ n = 2k
\end{cases}\]
\subsubsection*{Определение}
Пороговой точкой (BP) $\varepsilon^*_n$ оценки $\hat{\theta}$, построенной на выборке $X_1,\dots,\ X_n$ называется:
\[\varepsilon^*_n = \frac{1}{n} \max\left\{ m:\ \max_{i_1,\dots,\ i_m} \sup_{y_1,\dots,\ y_m} |\hat{\theta} (z_1,\dots,\ z_m)| < \infty \right\}\]
Где выборка $z_1,\dots,\ z_m$ получена заменой значений $X_{i_1},\dots,\ X_{i_m}$ на произвольные значения $y_1,\dots,\ y_m$
\subsection*{Доверительные интервалы}
\subsection*{Определение}
Пусть для $X_1,\dots,\ X_n \sim F(x,\ \theta),\ \theta \subset \Theta \subset \mathbb{R}^1$ построены статистики $T_1(x_1,\dots,\ x_n)$ и $T_2(x_1,\dots,\ x_n)$, такие что
\[\begin{cases}
T_1(x) < T_2(x)\\
P\big( T_1(x) < \theta < T_2(x)\big) = 1 - \alpha,\ 0 < \alpha < 1
\end{cases}\]
Тогда интервал $\big( T_1(x),\ T_2(x) \big)$ называется доверительным интервалом уровня надёжности (доверия) $1 - \alpha$ параметра $\theta$.
\subsection*{Определение}
Случайная функция $G(x_1,\dots,\ x_n,\ \theta) = G(x,\ \theta)$ называется центральной (опорной) статистикой, если 
\begin{enumerate}
    \item $G(x,\ \theta)$ непрерывна и монотонна по $\theta$
    \item $F_G(x)$ не зависит от $\theta$
\end{enumerate}
Односторонние доверительные интервалы:
\[P\big( G(x,\ \theta) < Z_{1 - \alpha} \big) = 1 - \alpha\]
\[P\big( Z_{\alpha} < G(x,\ \theta) \big) = 1 - \alpha\]
Квантили не зависят от $\theta$, с их помощью можно выразить односторонние доверительные интервалы.\\
Центральным доверительным интервалом будет:
\[P\big( Z_{\frac{\alpha}{2}} < G(x,\ \theta) < Z_{1 - \frac{\alpha}{2}} \big) = 1 - \alpha\]
\subsection*{Определение}
Пусть случайные величины $\xi_1,\dots,\ \xi_m \sim N(0,\ 1)$ и независимы.\\
Тогда случайная величина $\eta = \sum\limits_{i = 1}^{m} \xi_i^2 \sim \chi^2 (m)$ (удовлетворяет распределению хи-квадрат ($\chi^2$) с $m$ степенями свободы).
\subsection*{Определение}
Пусть $\xi_0,\ \xi_1,\dots,\ \xi_m \sim N(0,\ 1)$ и независимы.\\
Тогда случайная величина $\zeta = \frac{\xi_0}{\sqrt{\frac{1}{m} \sum_{i = 1}^{m} \xi_i^2}} \sim t(m)$ (распределение Стьюдента с $m$ степенями свободы)
\subsection*{Определение}
Пусть случайная величина $\xi_1 \sim \chi^2(m),\ \xi_2 \sim \chi^2(n)$ и $\xi_1$ и $\xi_2$ --- независимы. Тогда случайная величина $F = \frac{\frac{1}{m} \xi_1}{\frac{1}{n} \xi_2} \sim F(m,\ n)$ (распредление Фишера со степенями свободы $n,\ m$)
\subsection*{Теорема Фишера}
Пусть $X_1,\dots,\ X_n$ порождены случайной величиной $X \sim N(m,\ \sigma^2)$, тогда:
\begin{enumerate}
    \item $\frac{nS^2}{\sigma^2} = \sion \left( \frac{x_i - \overline{x}}{\sigma} \right)^2 \sim \chi^2(n - 1)$ (так как мы знаем $\overline{X}$, и все наблюдения, а по $n - 1$ наблюдению и $\overline{X}$ можно восстановить последнее наблюдение)
    \item $\overline{X}$ и $S^2$ --- независимые случайные величины.
\end{enumerate}
\subsection*{Пример 1}
$X_1,\dots,\ X_n \sim N(\theta,\ \sigma^2),\ \sigma^2$ --- известно. Построить доверительный инртервал для $\theta$
\[\hat{\theta} = \overline{X} \sim N(\theta,\ \frac{\sigma^2}{n})\]
\[ \frac{\sqrt{n} (\overline{X} - \theta)}{\sigma} \sim N(0,\ 1) \]
\[P\left( Z_{\frac{\alpha}{2}} < \frac{\sqrt{n} (\overline{X} - \theta)}{\sigma} < Z_{1 - \frac{\alpha}{2}} \right) = 1 - \alpha\]
Поскольку по середине стоит стандартное гауссовское распределение: $Z_{\frac{\alpha}{2}} = -Z_{1 - \frac{\alpha}{2}}$ 
\[P\left( -\frac{Z_{1 - \frac{\alpha}{2}}\sigma}{\sqrt{n}} - \overline{X} < -\theta < \frac{Z_{1 - \frac{\alpha}{2}} \sigma}{\sqrt{n}} - \overline{X} \right) = 1 - \alpha\]
\[P\left( \overline{X} - \frac{Z_{1 - \frac{\alpha}{2}}\sigma}{\sqrt{n}}  < \theta < \overline{X} + \frac{Z_{1 - \frac{\alpha}{2}} \sigma}{\sqrt{n}} \right) = 1 - \alpha\]
Итак, доверительный интервал: $\left( \overline{X} - \frac{Z_{1 - \frac{\alpha}{2}}\sigma}{\sqrt{n}},\ \overline{X} + \frac{Z_{1 - \frac{\alpha}{2}}\sigma}{\sqrt{n}}\right)$
\subsection*{Пример 2}
$X_1,\dots,\ X_n \sim N(m,\ \theta_2^2)$. Построить доверительный интервал для $\theta_2^2$
\[\sum_{i = 1}^n \left( \frac{x_i - m}{\theta_2} \right)^2 \sim \chi^2(n)\]
\[P\left(\chi^2_{n,\ \frac{\alpha}{2}} < \frac{\sion (x_i - m)^2}{\theta_2^2} < \chi^2_{n,\ 1 - \frac{\alpha}{2}}\right) = 1 - \alpha \]
\[P\left( \frac{\sion (x_i - m)^2}{\chi^2_{n,\ 1 - \frac{\alpha}{2}}} < \theta_2^2 < \frac{\sion (x_i - m)^2}{\chi^2_{n,\ \frac{\alpha}{2}}} \right) = 1 - \alpha\]
Здесь $\chi^2_{n,\ \alpha}$ --- квантиль уровня $\alpha$ распределения $\chi^2(n)$
\subsection*{Пример 3}
Если нам неизвестны оба параметра $N(\theta_1,\ \theta_2^2)$. Заменяем $m$ на $\overline{X}$:
Доверительный интервал для $\theta_2$:
\[P\left( \frac{\sion (x_i - \overline{X})^2}{\chi^2_{n,\ 1 - \frac{\alpha}{2}}} < \theta_2^2 < \frac{\sion (x_i - \overline{X})^2}{\chi^2_{n,\ \frac{\alpha}{2}}} \right) = 1 - \alpha\]
Доверительный интервал для $\theta_1$:
\[\frac{\sqrt{n} \left(\frac{\overline{X} - \theta}{\sigma}\right)}{ \sqrt {\frac{1}{n - 1} \sum\left(\frac{(x_i - \overline{X})}{\sigma} \right)^2}} = \frac{\sqrt{n} (\overline{X} - \theta_1)}{\tilde{S}} \sim t(n - 1)\]
Обозначим $t_{n,\ \alpha}$ квантиль уровня $\alpha$ распределения $t(n)$, заметим, что $t_{n,\ 1 - \alpha} = t_{n,\ 1 - \frac{\alpha}{2}}$
\[P(t_{n,\ 1 - \frac{\alpha}{2}} < \frac{\sqrt{n}(\overline{X} - \theta_1)}{\tilde{S}} < t_{n,\ \frac{\alpha}{2}} ) = 1 - \alpha\]
\[P(\overline{X} - \frac{\tilde{S}\cdot t_{n,\ 1 - \frac{\alpha}{2}}}{\sqrt{n}} < \theta_1 < \overline{X} + \frac{\tilde{S}\cdot t_{n,\ 1 - \frac{\alpha}{2}}}{\sqrt{n}} ) = 1 - \alpha\]
\begin{center}
    Лекция 7 февраля
\end{center}
\subsection*{Задача}
$X_1,\dots,\ X_{n_1} \sim N(m_1,\ \sigma_1^2)$ и $Y_1,\dots,\ Y_{n_2} \sim N(m_2,\ \sigma_2^2)$. $\sigma$ известны, $m$ --- неизвестны.\\
$X_1,\dots,\ X_n$ и $Y_1,\dots,\ Y_n$ независимы. Доверительнный интервал для $\theta = m_1 - m_2$
\[T(x,\ y) = \frac{\overline{X} - \overline{Y} - \theta}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}\]
\subsection*{Задача}
Пусть $X_1,\dots,\ X_{n_1} \sim N(m_1,\ \sigma^2),\ Y_1,\dots,\ Y_{n_2} \sim N(m_2,\ \sigma^2)$. $\sigma$ неизвестна. Выборки независимы.
\subsubsection*{Утверждение}
\[\frac{\sum_{i = 1}^{n_1} {(x_i - \overline{X})}^2}{\sum_{i = 1}^{n_2}{(y_i - \overline{Y})}^2} \sim F(n_1 - 1,\ n_2 - 1)\]
\[\frac{\overline{X} - \overline{Y} - (m_1 - m_2)}{\sqrt{\hat\dev (\overline{X} - \overline{Y})}}\]
Посчитаем дисперсию в знаменателе:
\begin{equation*}
    \begin{aligned}
        \dev (\overline{X} - \overline{Y}) &= \dev \overline{X} + \dev \overline{Y} = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2} = \sigma^2\left( \frac{1}{n_1} + \frac{1}{n_2} \right)\\
        S^2 &= \frac{\sum_{i = 1}^{n_1} {(x_i - \overline{X})}^2 + \sum_{i = 1}^{n_2} {(y_i - \overline{Y})}^2 }{n_1 + n_2 - 2}
    \end{aligned}    
\end{equation*}
Тогда
\[\frac{\overline{X} - \overline{Y} - (m_1 - m_2)}{\sqrt{\hat\dev (\overline{X} - \overline{Y})}} = \frac{\overline{X} - \overline{Y} - (m_1 - m_2)}{S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t(n_1 + n_2 - 2)\]
Теперь можно построить доверительный интервал:
\[P\left( -t_{1 - \alpha/2,\ n_1 + n_2 - 2} < \frac{\overline{X} - \overline{Y} - \theta}{S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} < t_{1 - \alpha/2,\ n_1 + n_2 - 2}\right) = 1 - \alpha\]
\[P\left(-t_{1 - \alpha/2,\ n_1 + n_2 - 2}\cdot S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}} - (\overline{X} - \overline{Y}) < -\theta < t_{1 - \alpha/2,\ n_1 + n_2 - 2}\cdot S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}} - (\overline{X} - \overline{Y})\right) = 1 - \alpha\]
\[P\left((\overline{X} - \overline{Y}) -t_{1 - \alpha/2,\ n_1 + n_2 - 2}\cdot S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}  < \theta < t_{1 - \alpha/2,\ n_1 + n_2 - 2}\cdot S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}} + (\overline{X} - \overline{Y})\right) = 1 - \alpha\]
\subsection*{Асимптотические доверительные интервалы}
Пусть $X_1,\dots,\ X_n\sim F(x,\ \theta),\ \theta \in \Theta \subset \mathbb{R}^1$\\
$\hat \theta$ --- состоятельная оценка $\theta$.
\[\sqrt{n}(\hat\theta_n - \theta) \xrightarrow[n\to\infty]{d} U,\ U \sim N\big(0,\ \sigma^2 (\theta)\big)\]
И $\sigma^2(\theta)$ непрерывна по $\theta$.
\[P\left( Z_{\alpha/2} < \frac{\sqrt{n}(\hat \theta_n - \theta)}{\sigma(\hat\theta_n)} < Z_{1 - \alpha/2} \right) \to 1 - \alpha\]
\[P\left( \hat\theta_n - \frac{\sigma(\hat\theta_n) Z_{1 - \alpha/2}}{\sqrt{n}} < \theta < \frac{\sigma(\hat\theta_n) Z_{1 - \alpha/2}}{\sqrt{n}} + \hat\theta_n\right)\]
Если $\exists$ R-эффективная оценка $\hat \theta_n$, то выбирая её $\dev \hat \theta_n = \frac{1}{I_n(\theta)}$, тогда $\frac{\sigma(\hat\theta_n)}{\sqrt{n}} = \sqrt{\dev \hat\theta_n} = \frac{1}{\sqrt{nI_1(\hat\theta_n)}}$
\[P\left( \hat\theta_n - \frac{Z_{1 - \alpha/2}}{\sqrt{n I_1 (\hat \theta_n)}} < \theta < \hat\theta_n + \frac{ Z_{1 - \alpha/2}}{\sqrt{n I_1(\hat \theta_n)}} \right) \to 1 - \alpha\]
\subsection*{Пример}
$X_1,\dots,\ X_n \sim Bi(1,\ \theta)$\\
АДИ для $\theta$:
\[\hat\theta = \frac{\sum_{i = 1}^{n} x_i}{n} - \text{несмещённая, состоятельная, R-эффективная}\]
$\dev x_i = \theta(1 - \theta)$.
\[\sqrt{n} (\hat \theta - \theta) \xrightarrow[n\to \infty]{d} U,\ U\sim N\big(0,\ \theta(1 - \theta)\big)\]
\[P\left( \hat\theta - Z_{1 - \alpha/2} \sqrt{\frac{\hat\theta(1 - \hat\theta)}{n}} < \theta < \hat \theta + Z_{1 - \alpha/2} \frac{\sqrt{\hat{\theta}(1 - \hat \theta)}}{\sqrt{n}} \right) \to 1 - \alpha\]
\subsection*{Определение}
Основная (или нулевая) гипотеза $H_0$, с ней конкурируют $H_1,\ H_2,\dots,\ H_{A}$ (альтернативные гипотезы).
\subsection*{Определение}
Сложной гипотезой называют гипотезу, которая не определяет параметры распределения или само распределение однозначно.\\
Например
\[H_1: \xi \sim N(m,\ \sigma^2)\]
\[H_2: \xi \sim N(5,\ \sigma^2)\]
Простая гипотеза определяет распределение однозначно, например:
\[H_3: \xi \sim N(5,\ 36)\]
Односторонние гипотезы выглядят так:
\[H_4: \xi m < 5\]
\[H_5: \xi m > 5\]
Двусторонние:
\[H_6: n \neq 5\]
\[H_7: m\in [1,\ 3]\]
А гипотеза $H_8: \{\text{``Сегодня хорошая погода''}\}$ не является статистической, ведь не относится к распределению и параметрам.
\subsection*{Определение}
Статистическим критерием называют правило, руководствуясь которым, на основании реализации $x_1,\dots,\ x_n$ выборки $X_1,\dots,\ X_n$ принимается решение о справедливости/несправедливости гипотезы $H_0$.\\
Делим множество реализаций выборки $S$ на два множества $S_0,\ S_1$, такие что
\[S_0 \cdot S_1 = \emptyset\]
\[S_0 + S_1 = S\]
Назовём $S_0$ доверительной областью, а $S_1$ --- критической областью. Если реализация попала в $S_0$, то мы принимаем $H_0$, иначе принимает альтернативную гипотезу.\\
Тогда ошибкой первого рода (уровнем значимости критерия) называется
\[P(X\in S_1\ |\  \text{верна } H_0) = \alpha\]
Ошибкой второго рода называется 
\[P(X\in S_0 \wedge \text{верна } H_1) = 1 - \beta\]
\subsection*{Определение}
Пусть критерий предназначен для проверки $H_0: \theta = \theta_0$ против альтернативы $H_1: \theta \neq \theta_0$, тогда функцией мощности критерия называется
\[\beta(\theta) = P(X \in S_1,\ \theta)\]
Критерий называется состоятельным, если при отдалении от $\theta_0$ его функция мощности стремится к $1$.
\end{document}
