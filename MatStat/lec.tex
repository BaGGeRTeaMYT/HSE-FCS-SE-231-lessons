\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage[margin=0.25in]{geometry}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\usepackage{nicefrac}
\graphicspath{../Images}
\usepackage{tikz}
\usepackage{cancel}

\usepackage{fontspec}
\setmainfont{Times New Roman}

\newcommand{\sion}{\sum\limits_{i = 1}^{n}}
\newcommand{\dev}{\mathcal{D}}
\newcommand{\cov}{\operatorname{cov}}

\title{Математическая статистика.}
\author{Андрей Тищенко \href{https://t.me/AndrewTGk}{@AndrewTGk}}
\date{2024/2025}

\begin{document}
\maketitle
\begin{center}
    Лекция 10 января
\end{center}
\section*{Преамбула}
\textit{Статистика}. Мнения о появлении этого слова:
\begin{enumerate}
    \item Статистиками в Германии назывались люди, собирающие данные о населении и передающие их государству.
    \item В определённый день в Венеции народ выстраивался для выплаты налогов (строго фиксированных, в зависимости от рода действий). Государство собирало данные обо всём населении. Это происходило до появления статистиков в Германии, поэтому мы будем считать, что статистика пошла из Венеции.
\end{enumerate}
\textit{Задача статистики} --- по результатам наблюдений построить вероятностную модель наблюдаемой случайной величины.
\section*{Основные определения}
\subsection*{Определение}
\underline{Однородной выборкой объёма $n$} называется случайный вектор $X = (X_1,\dots,\ X_n)$, компоненты которого являются независимыми и одинаково распределёнными. Элементы вектора $X$ называются \underline{элементами}\\\underline{выборки}. 
\subsection*{Определение}
Если элементы выборки имеют распределение $F_{\xi}(x)$, то говорят, что выборка \underline{соответствует распределению} $F_{\xi}(x)$ или \underline{порождена случайной величиной} $\xi$ с распределением $F_{\xi}(x)$. 
\subsection*{Определение}
Детерминированный вектор $x = (x_1,\dots,\ x_n)$, компоненты которого $x_i$ являются реализациями соответствующих случайных величин $X_i\ (i = \overline{1,\ n})$, называется \underline{реализацией выборки}.
\subsection*{Уточнение}
Если $X$ --- однородная выборка объёма $n$, то его реализацией будет вектор $x$, каждый элемент $x_i$ которого является значением соответствующей ему случайной величины (элемента выборки) $X_i$. 
\subsection*{Определение}
\underline{Выборочным пространством} называется множество всех возможных реализаций выборки\\
\[X = (X_1,\dots,\ X_n)\]
\subsection*{Пример}
У вектора $X = (X_1,\dots,\ X_{10})$ каждый элемент $X_i$ которой порождён случайной величиной $\xi\sim U(0,\ 1)$, выборочным пространством является $\mathbb{R}^{10}$ (так как $X_i$ может принять любое значение на $\mathbb{R}$)
\subsection*{Определение}
Обозначим $x_{(i)}$ --- $i$-ый по возрастанию элемент, тогда будет справедливо:
\[x_{(1)} \leq x_{(2)} \leq \dots \leq x_{(n)}\]
Обозначим $X_{(k)}$ случайную величину, реализация которой при каждой реализации $x$ выборки $X$ принимает значение $x_{(k)}$. Тогда последовательность $X_{(1)},\dots,\ X_{(n)}$ называется \underline{вариационным рядом выборки}.
\subsection*{Определение}
Случайная величина $X_{(k)}$ называется \underline{$k$-ой порядковой статистикой выборки}.
\subsection*{Определение}
Случайные величины $X_{(1)},\ X_{(n)}$ называются \underline{эстремальными порядковыми статистиками}.
\subsection*{Определение}
Порядковая статистика $X_{(\lceil n\cdot p \rceil)}$ называется \underline{выборочной квантилью уровня $p$}, где $p\in [0,\ 1]$
\subsection*{Определение}
Пусть каждый элемент выборки $X$ объёма n имеет распределение $F_{\xi}(x)$. \underline{Эмпирической функцией}\\ \underline{распределения} такой выборки называется
\[\hat{F}_n(x) = \frac{1}{n} \sum_{k = 1}^{n} I(X_k\leq x)\]
$I$ --- индикаторная функция. $I = \begin{cases}
    1,\ \text{если аргумент верен}\\
    0,\ \text{иначе}
\end{cases}$\\
Пусть $x_1,\dots,\ x_n$ --- реализация выборки $X_1,\dots,\ X_n$\\
\[\begin{tikzpicture}[scale=2, >=latex]
    \draw[->, >=latex] (0, -1) -- (0, 1) node(0)[anchor = east]{$\hat{F}_n(x)$};
    \draw (-2, -0.05) node(1)[anchor=north]{$x_1$} -- (-2, 0.05);
    \draw (-1, -0.05) node(2)[anchor=north]{$x_2$}-- (-1, 0.05);
    \draw (0.07, -0.05) node(3)[anchor=north east]{$x_3$}-- (0.07, -0.05);
    \draw (1, -0.05) node(4)[anchor=north]{$x_4$}-- (1, 0.05);
    \draw (2, -0.05) node(5)[anchor=north]{$x_5$}-- (2, 0.05);
    \draw[->] (-3, 0) -- (-2, 0);
    \draw[->] (-2, 0.2) -- (-1, 0.2);
    \draw[dashed] (-2, 0) -- (-2, 0.2);
    \draw[->] (-1, 0.45) -- (0, 0.45);
    \draw[dashed] (-1, 0) -- (-1, 0.45);
    \draw[->] (0, 0.6) -- (1, 0.6);
    \draw[dashed] (1, 0) -- (1, 0.85);
    \draw[->] (1, 0.85) -- (2, 0.85);
    \draw[dashed] (2, 0) -- (2, 1);
    \draw[->] (2, 1) -- (3, 1);
    \draw[->] (-3, 0) -- (3, 0) node(2)[anchor = south]{$x$};
\end{tikzpicture}\]
\begin{center}
    Свойства $\hat{F}_n(x)$
\end{center}
\begin{enumerate}
    \item $\displaystyle\forall x\in\mathbb{R}\quad E\hat{F}_n(x) = E\left(\frac{1}{n} \sum_{k = 1}^{n} I(X_k \leq x)\right) = \frac{1}{n} \sum_{k = 1}^{n} EI(X_k \leq x) = P(X_1 \leq x) = F_{\xi}(x)$
    \item По усиленному закону больших чисел (УЗБЧ)
    \[\forall x\in \mathbb{R}\quad \hat{F}_n(x) = \frac{1}{n} \sum_{k = 1}^{n} I(X_k \leq x) \xrightarrow[n\to\infty]{\text{п. н.}} EI(X_k \leq x) = F_{\xi}(x)\]
\end{enumerate}
\subsection*{Гистограмма}
Разбить $\mathbb{R}$ на $(m + 2)$ непересекающихся интервала. Рассматриваются $x_{(1)},\dots,\ x_{(m)}$
\[\begin{tabular}{|c|c|c|}
    \hline
    Название & Обозначение & Формула\\
    \hline
    $\begin{aligned}&\text{Количество}\\&\text{интервалов}\end{aligned}$ & $m$ & ---\\
    \hline
    $\begin{aligned}&\text{Размах}\\&\text{выборки}\end{aligned}$ & $r$ & $r = x_{(m)} - x_{(1)}$\\
    \hline
    $\begin{aligned}&\text{Ширина}\\&\text{интервала}\end{aligned}$ & $\Delta$ & $\Delta = \frac{r}{m}$\\
    \hline
    $\begin{aligned}&\text{Количество}\\&\text{попаданий на}\\&\text{$i$-ый интервал}\end{aligned}$ & $\nu_i$ & ---\\
    \hline
    $\begin{aligned}&\text{Частота}\\&\text{попаданий на}\\&\text{$i$-ый интервал}\end{aligned}$ & $h_i$ & $h_i = \frac{\nu_i}{\Delta}$\\
    \hline
\end{tabular}\quad
\begin{tikzpicture}[scale=2, >=latex]
    \draw[->] (-2, 0) -- (2, 0) node(2)[anchor = south]{$x$};
    \draw (-1.5, -0.1) node[anchor=north](4){$x_{(1)}$} -- (-1.5, 0.1) node(3){};
    \draw (1.5, -0.1) node[anchor=north](6){$x_{(m)}$} -- (1.5, 0.1) node(5){};
    \draw[<->] (-1.5, -0.08) -- node[anchor=north](10){$r$} (1.5, -0.08);
    \draw (0.75, -0.05) -- (0.75, 0.05) node(6){};
    \draw[<->] (-0.75, 0.08) -- node[anchor=south](11){$\Delta$} (0, 0.08);
    \draw (0, -0.05) -- (0, 0.05) node(8){};
    \draw (-0.75, -0.05) -- (-0.75, 0.05) node(9){};
    \draw (-1.5, 0) rectangle (-0.75, 0.5);
    \draw[->] (0.375, 0) -- node(0)[anchor = west]{$h_i$} (0.375, 0.75);
    \draw (-0.75, 0) rectangle (-0.0, 0.8);
    \draw (-0.0, 0) rectangle (0.75, 0.75);
    \draw (0.75, 0) rectangle (1.5, 0.2);
\end{tikzpicture}\]
\begin{center}
    Лекция 17 января
\end{center}
\subsection*{Определение}
Пусть $X_1,\dots,\ X_n \sim F(x,\ \theta)$. \underline{$k$-ым начальным выборочным моментом} называется \[\hat{\mu}_k = \frac{1}{n} \sum_{i = 1}^{n} x_i^k,\ k \in \mathbb{N}\]
\underline{Выборочным средним} называется:
\[\hat{\mu}_1 = \overline{x} = \frac{1}{n} \sum_{i = 1}^{n} x_i\]
\subsection*{Определение}
\underline{$k$-ым центральным выборочным моментом} называется 
\[\hat{\nu}_k = \frac{1}{n} \sum_{i = 1}^{n} (x_i - \overline{x})^k,\ k = 2,\ 3,\dots\]
\[\hat{\nu}_2 = S^2 = \frac{1}{n} \sum_{i = 1}^{n} (x_i - \overline{x})^2 \text{ называется выборочной дисперсией}\]
Пусть $(x_1,\ y_1),\dots,\ (x_n,\ y_n)$ соответствует распределению $F(x,\ y,\ \theta)$
\subsection*{Определение}
\underline{Выборочной ковариацией} называется
\[\hat{K}_{xy} = \frac{1}{n}\sum_{i = 1}^{n} (x_i - \overline{x}) (y_i - \overline{y})\]
\subsection*{Определение}
\underline{Выборочным коэффициентом корреляции} называется 
\[\hat{\rho}_{xy} = \frac{\hat{K}_{xy}}{\sqrt{S_x^2 S_y^2}}\]
\begin{center}
    Свойства выборочных моментов
\end{center}
\begin{enumerate}
    \item $E\hat{\mu}_k = E\left( \frac{1}{n} \sum_{i = 1}^{n} X_i^k \right) = \frac{1}{n} \sum_{i = 1}^{n} E X_i^k = EX_1^k = \mu_k$
    \item $E\overline{X} = m_x$
    \item $\mathcal{D} \hat{\mu}_k = \mathcal{D} \left( \frac{1}{n} \sum_{i = 1}^{n} x_i^k \right) = \frac{1}{n^2} \sum_{i = 1}^{n} \mathcal{D} X_i^k = \frac{1}{n} \mathcal{D} X_i^k = \frac{1}{n} \left( EX_1^{2k} - (EX_1^{K})^2 \right) = \frac{1}{n}(\mu_{2k} - \mu_k^2)$
    \item $\mathcal{D}\overline{x} = \frac{\sigma^2_{x_1}}{n}$
    \item По УЗБЧ
    \[\hat{\mu}_k = \frac{1}{n} \sum_{i = 1}^{n} x_i^k \xrightarrow[n\to \infty]{\text{п. н.}} E\hat{\mu}_k = \mu_k\]
    \[\hat{\nu}_k \xrightarrow[n\to \infty]{\text{п. н.}} \nu_k\]
    \item По ЦПТ
    \[\frac{\hat{\mu}_k - \mu_k}{\sqrt{\frac{\mu_{2k} - \mu_k^2}{n} }}\xrightarrow[d]{n\to\infty}U,\ U\sim N(0,\ 1)\]
    \[\frac{\sqrt{n}(\overline{x} - m_{x_1})}{\sigma} \xrightarrow[n\to\infty]{d} U\]
    \item $ES^2 = E\left( \frac{1}{n} \sum_{i = 1}^{n}(x_i - \overline{x})^2 \right) = \frac{n - 1}{n} \sigma^2$
    \item $E \hat{K}_{xy} = \frac{n - 1}{n} \cov(x,\ y)$
\end{enumerate}
\subsection*{Определение}
Оценкой $\hat{\theta}$ параметра $\theta$, называется функция:
\[\hat{\theta} = T(x_1,\dots,\ x_n),\ \text{не зависящая от $\theta$}\]
Например, отвратительная оценка среднего роста людей в аудитории.
\[\hat{m} = \frac{2x_2 + 5x_5 + 10x_{10}}{3}\]
\subsection*{Определение}
Оценка $\hat{\theta}$ называется \underline{несмещённой}, если $E\hat{\theta} = \theta$ для любых возможных значений этого параметра.
\subsection*{Определение}
Оценка $\hat{\theta}(x_1,\dots,\ x_n)$ называется \underline{асимптотически несмещённой оценкой} $\theta$, если
\[\lim_{n\to\infty} E\hat{\theta}(x_1,\dots,\ x_n) = \theta\]
\[\lim_{n\to\infty} ES^2 = \lim_{n\to\infty} \frac{n - 1}{n}\sigma^2 = \sigma^2\]
\subsection*{Определение}
\underline{Несмещённой выборочной} (или исправленной) \underline{выборочной дисперсией} называется
\[\tilde{S}^2 = \frac{1}{n - 1} \sum_{i = 1}^{n} (x_i - \overline{x})^2\]
Оценки
\[\begin{aligned}
    \hat{m}_1 &= \frac{x_1 + x_2 + x_3}{3}\\
    \hat{m}_2 &= \frac{\sum_{i = 1}^{10} x_i}{10}\\
    \hat{m}_3 &= \overline{x} = \frac{\sion x_i}{n}\\  
\end{aligned}\]
Являются несмещёнными.
\subsection*{Определение}
Оценка $\hat{\theta}(x_1,\dots,\ x_n)$ называется:\\
\underline{Состоятельной оценкой} $\theta$, если
\[\hat{\theta} (x_1,\dots,\ x_n) \xrightarrow[n\to\infty]{p} \theta\]
\underline{Сильно состоятельной оценкой}, если
\[\hat{\theta} (x_1,\dots,\ x_n) \xrightarrow[n\to\infty]{\text{п. н.}} \theta\]
\subsection*{Определение}
Пусть $\hat{\theta}$ --- несмещённая оценка параметра $\theta$. Если $\dev\hat{\theta} \leq \dev \theta^*$, где $\theta^*$ --- любая несмещённая оценка параметра $\theta$. Тогда $\hat{\theta}$ называется \underline{эффективной оценкой параметра} $\theta$.
\begin{center}
    $R$-эффективные оценки
\end{center}
Рассматриваем выборку $X_1,\ldots,\ X_n \sim f(x,\ \theta),\ \theta\in \Theta \subseteq \mathbb{R}^1$. Назовём модель $(S,\ f(x,\ \theta))$ \underline{регулярной}, если она удовлетворяет следующим условиям:
\begin{enumerate}
    \item $\forall x\in S\quad \text{функция } f(x,\ \theta) = f(x_1,\dots,\ x_n,\ \theta) > 0$ и дифференцируема по $\theta$.
    \item $\displaystyle\frac{\delta}{\delta \theta} \int\limits_S f(x,\ \theta)\, dx = \int\limits_S \frac{\delta}{\delta \theta} f(x,\ \theta)\, dx = \frac{\delta}{\delta \theta} \int\limits_S T(x)f(x,\ \theta)\, dx = \int\limits_S \frac{\delta}{\delta \theta} T(x) f(x,\ \theta)\, dx$
\end{enumerate}
Пусть $\hat{\theta} = T(x) = T(x_1,\dots,\ x_n)$ --- несмещённая оценка параметра $\theta$:
\[\int\limits_S \frac{\delta}{\delta \theta} f(x,\ \theta)\, dx = 0,\ \text{так как не зависит от $\theta$}\]
\[\int\limits_S \frac{\delta}{\delta \theta} T(x) f(x,\ \theta)\, dx = \frac{\delta}{\delta \theta}\theta = 1\]
\subsection*{Определение}
\underline{Информацией Фишера} о параметре $\theta$, содержащейся в выборке $X_1,\dots,\ X_n$ называется величина
\[I_n(\theta) = E\left( \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} \right)^2 = \int\limits_S\left( \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} \right)^2 f(x,\ \theta)\, dx\]
\subsection*{Неравенство Рао-Крамера}
Если $S,\ f(x,\ \theta)$ --- регулярная модель и $\hat{\theta}$ --- несмещённая оценка $\theta$, то 
\[\dev (\hat{\theta}) \geq \frac{1}{I_n(\theta)}\]
Докажем это неравенство.
\subsubsection*{Неравенство Коши-Буняковского}
\[\left( \int \varphi_1(x)\varphi_2(x)\, dx \right)^2 \leq \int \varphi_1^2(x)\, dx\int \varphi_2^2(x)\, dx\]
Пользуясь этим:
\[\int\limits_S \frac{\delta}{\delta \theta} f(x,\ \theta)\, dx = \int\limits_S \frac{\delta f(x,\ \theta)}{\delta \theta} \frac{f(x,\ \theta)}{f(x,\ \theta)}\, dx = \int\limits_S \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx = 0\]
\[\int\limits_S \frac{\delta}{\delta \theta} T(x) f(x,\ \theta)\, dx = \int\limits_S T(x) \frac{\delta}{\delta \theta} f(x,\ \theta) \frac{f(x,\ \theta)}{f(x,\ \theta)}\, dx = \int\limits_S T(x) \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta)\, dx = 1\]
Применяя неравенство Коши-Бунякоского:
\[1 = \int\limits_S \big( T(x) - \theta \big) \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} f(x,\ \theta)\, dx \leq \underset{=\dev\hat{\theta}}{\underbrace{\int\limits_S \big( T(x) - \theta \big)^2 f(x,\ \theta)\, dx}} \cdot \underset{=I_n(\theta)}{\underbrace{\int\limits_S\left( \frac{\delta \ln \big(f(x,\ \theta)\big)}{\delta \theta} \right)^2 f(x,\ \theta)\, dx}}\]
Получили
\[1 \leq \dev (\theta) \cdot I_n(\theta)\Rightarrow \dev (\theta) \geq \frac{1}{I_n(\theta)}\]
\subsection*{Определение}
Оценка $\hat{\theta}$ называется \underline{$R$-эффективной}, если $E\hat{\theta} = \theta$ и $\dev \hat{\theta} = \frac{1}{I_n(\theta)}$
\begin{center}
    Лекция 24 января
\end{center}
\subsection*{Замечание 1}
$I_n(\theta) = \dev \left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \right)$
\subsection*{Замечание 2}
$I_n(\theta) = nI_1(\theta)$\\
$\displaystyle f(x,\ \theta) = f(x_1,\dots,\ x_n,\ \theta) = \prod_{i = 1}^{n} f(x_i,\ \theta)\\
E\left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \right)^2 = E \left( \sion \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta} \right)^2 = \sum_{i \neq j} E \left( \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta} \cdot \frac{\delta \ln f(x_j,\ \theta)}{\delta \theta} \right) + nE\left( \frac{\delta \ln f(x_1, \theta)}{\delta \theta} \right)^2 =\\
= \sum_{i \neq j} \left( \underset{=0}{\underbrace{E \left( \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta}\right)}} \cdot \underset{=0}{\underbrace{E\left( \frac{\delta \ln f(x_j,\ \theta)}{\delta \theta} \right)}}\right) + nE\left( \frac{\delta \ln f(x_1, \theta)}{\delta \theta} \right)^2 = nE\left( \frac{\delta \ln f(x_1, \theta)}{\delta \theta} \right)^2 = nI_1(\theta)$
\subsection*{Замечание 3}
Пример: $X_1,\dots,\ X_n \sim N(\theta,\ \sigma^2)$\\
Рассмотрим оценку $\hat{\theta} = \overline{X}$, её дисперсия $\mathcal{D}\overline{X} = \frac{\sigma^2}{n}$. Посчитаем информацию Фишера:\\
$I_1(\theta) = E\left( \frac{\delta \ln f(x,\ \theta)}{\delta \theta} \right)^2 = E\left( \frac{\delta}{\delta \theta} \ln\left( \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x - \theta)^2}{2\sigma^2}}\right) \right)^2 = E\left( \frac{\delta}{\delta \theta} \ln\left( \frac{1}{\sqrt{2\pi} \sigma} - \frac{(x - \theta)^2}{2\sigma^2} \right) \right)^2 = E\left( \frac{x - \theta}{\sigma^2} \right)^2 = \\
=\frac{1}{\sigma^4} E(x - \theta)^2 = \frac{\sigma^2}{\sigma^4} = \frac{1}{\sigma^2}\Rightarrow I_n(\theta) = \frac{n}{\sigma^2}$\\
Знаем, что $\mathcal{D}\hat{\theta} \geq \frac{1}{nI_1(\theta)} = \frac{\sigma^2}{n} = \mathcal{D}(\overline{X})\Rightarrow$ оценка $\hat{\theta} = \overline{X}$ является R-эффективной.\\
Критерий эффективности $X_1,\dots,\ X_n \sim F_{\xi}(x,\ \theta),\ \theta \in \Theta \subset \mathbb{R}^1$ выполнены условия регулярности, то есть
\[ \int T(x)\frac{\delta f(x,\ \theta)}{\delta \theta}\, dx = \frac{\delta}{\delta \theta} \int T(x) f(x,\ \theta)\, dx = E\hat{\theta}\]

\subsection*{Определение}
Функцией вклада выборки $X_1,\dots,\ X_n$ называется
\[U(x,\ \theta) = \sion \frac{\delta \ln f(x_i,\ \theta)}{\delta \theta}\]
Пусть $0 < U(x, \theta) < \infty$.\\
$\hat{\theta} = T(x_1,\dots,\ x_n)$ --- R-эффективная оценка $\theta \Leftrightarrow \hat{\theta} - \theta = a(\theta) U(x,\ \theta)$, где $a(\theta) = \mathcal{D}\hat{\theta}$\\
\textit{Доказательство} $\Rightarrow$:\\
Пусть $\hat{\theta} - \theta = a(\theta) U(x,\ \theta) \Rightarrow \hat{\theta}$ --- R-эффективная оценка $\theta$.\\
Посчитаем математическое ожидание частей равенства:
\[E(\hat{\theta} - \theta) = a(\theta) EU(x,\ \theta) = a(\theta) \int \frac{\delta \ln f(x,\ \theta)}{\delta \theta} f(x,\ \theta) dx = 0\]
Посчитаем дисперсию частей:
\[\dev (\hat{\theta} - \theta) = a^2(\theta) \dev U(x,\ \theta) = \underset{=(\dev(\hat{\theta}))^2}{\underbrace{a^2(\theta)}} I_n(\theta)\Rightarrow \dev(\hat{\theta}) = (\dev(\hat{\theta}))^2 I_n(\theta)\Rightarrow 1 = \dev(\theta) I_n(\theta)\]
Значит оценка является R-эффективной.\\
\textit{Доказательство} $\Leftarrow$:\\
Пусть $\hat{\theta}$ --- R-эффективная оценка $\Rightarrow \hat{\theta} - \theta = a(\theta) U(x,\ \theta)$. Хотим доказать, что $\rho(\hat{\theta},\ U(x,\ \theta)) = 1$.\\
Для подсчёта корреляции нужно посчитать ковариацию:
\[\cov (\hat{\theta},\ U(x,\ \theta)) = E(\hat{\theta} - \theta) U(x,\ \theta) = E\hat{\theta} U(x,\ \theta) - \theta \underset{=0}{\underbrace{EU(x,\ \theta)}} =\]
\[= \int\limits_S T(x)U(x,\ \theta) f(x,\ \theta)\, dx = \int\limits_S T(x) \frac{\delta \ln f(x,\ \theta)}{\delta \theta}f(x,\ \theta)\, dx = 1\]
Так как $\hat{\theta}$ --- R-эффективная оценка, то $\dev \hat{\theta} = \frac{1}{I_n(\theta)}$. Знаем, что $\dev U(x,\ \theta) = I_n(\theta)$, тогда:
\[\rho(\hat{\theta},\ U(x,\ \theta)) = \frac{\cov (\hat{\theta},\ U(,\ \theta))}{\sqrt{\dev \hat{\theta} \dev U(x,\ \theta)}} = \frac{1}{\sqrt{\frac{I_n(\theta)}{I_n(\theta)}}} = 1\Rightarrow\]
\[\Rightarrow \hat{\theta} = c_1 + c_2U(x,\ \theta)\]
$E\hat{\theta} = c_1 + Ec_2 U(x,\ \theta) = c_1 + 0 = \theta$, так как оценка эффективная\\
$\dev \hat{\theta} = c_2^2 I_n(\theta) = \frac{1}{I_n(\theta)}\Rightarrow c_2^2 = \frac{1}{I_n^2}\Rightarrow c_2 = \frac{1}{I_n} = \dev\hat{\theta} = a(\theta)$.\\
Итак, $\hat{\theta} = \theta + a(\theta) U(x,\ \theta)\Rightarrow \hat{\theta} - \theta = U(x,\ \theta)$.
\subsection*{Метод моментов}
$X_1,\dots,\ X_n\sim F_{\xi}(x,\ \theta),\ \theta \in \Theta\subset R^k$
\[\exists \mu_j < \infty,\ j = \overline{1,\ k}\quad \underset{=\mu_j(\theta)}{\underbrace{\mu_j}} = E\xi^j = \int\limits_{-\infty}^{+\infty} x^j f(x,\ \theta)\, dx = 1\]
Тогда можно получить систему уравнений:
\begin{equation}
    \begin{cases}
        \hat{\mu_1} = \mu_1(\theta)\\
        \vdots\\
        \hat{\mu_n} = \mu_n(\theta)
    \end{cases}
\end{equation}
Если система уравнений $(1)$ однозначно разрешима относительно $\theta_1,\dots,\ \theta_k$, то решения $\hat{\theta_1},\dots,\ \hat{\theta_k}$ называется равной $\theta_1,\dots,\ \theta_k$ по методу моментов.
\subsubsection*{Пример}
$X_1,\dots,\ X_n \sim N(\theta_1,\ \theta_2^2),\ \theta = (\theta_1,\ \theta_2^2)$, тогда:
\[\begin{cases}
    \hat{\mu_1} = \frac{1}{n} \sion x_i = \theta_1\Rightarrow \hat{\theta_1} = \overline{X}\\
    \hat{\mu_2} = \frac{1}{n} \sion x_i^2 = \theta_2^2 + \theta_1^2,\ \big(E\xi^2 = \dev \xi + (E\xi)^2\big)\Rightarrow \hat{\theta}_2^2 = \frac{1}{n}\sion  x_i^2 = \overline{X}^2
\end{cases}\]
\subsection*{Метод максимального правдоподобия (ММП)}
\subsubsection*{Определение}
Функцией правдоподобия называется функция 
\[L(x_1,\dots,\ x_n,\ \theta) = \begin{cases}
    \prod\limits_{i = 1}^{n} f(x_i,\ \theta),\ \text{если $\xi$ --- непрерывная случайная величина}\\
    \prod\limits_{i = 1}^{n} P(\xi = x_i,\ \theta),\ \text{если $\xi$ --- дискретная случайная величина}
\end{cases}\]
\subsubsection*{Определение}
Реализацией оценки максимального правдоподобия (ОМП) называется значение $\hat{\theta} \in \Theta$, такое что:
\[\hat{\theta} = \operatorname{argmax} L(x_1,\dots,\ x_n,\ \theta),\ \text{где }\theta \in \Theta\]
Для нахождения точки максимума нужно взять частные производные по всем составляющим $\theta$ от функции правдоподобия. Однако считать производную произведения нам впадлу, поэтому мы введём следующую вещь:
\subsubsection*{Определение}
Функция $\ln L(x_1,\dots,\ x_n,\ \theta)$ называется логарифмической функцией правдоподобия.\\
Итак, получаем систему уравнений:
\[\begin{cases}
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{\delta \theta_1} = 0\\
    \vdots\\
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{\delta \theta_k} = 0
\end{cases}\]
Логарифм монотонный, поэтому его argmax совпадёт с argmax функции $L(x_1,\dots,\ x_n,\ \theta)$ (НАУКА!).
\subsubsection*{Пример}
Для Гауссовской величины $N(\theta_1,\ \theta_2^2)$:
\[L(x_1,\dots,\ x_n,\ \theta) = \prod\limits_{i = 1}^{n} \frac{1}{\sqrt{2\pi}\sigma^2} e^{-\frac{(x - \theta^1)^2}{2\theta_2^2}} = \left( \frac{1}{\sqrt{2\pi}} \right)^n \left( \frac{1}{\theta_2} \right)^n e^{-\frac{(x - \theta_1)^2}{2\theta_2^2}}\]
Логарифмируем:
\[\ln L(x_1,\dots,\ x_n,\ \theta) = \ln \left( \frac{1}{\sqrt{2\pi}} \right)^n - n\ln \theta_2 - \frac{\sion (x_i - \theta_1)^2}{2\theta_2^2}\]
Возьмём частные производные:
\[\begin{cases}
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{ \delta \theta_1} = \frac{\sion (x_i - \hat{\theta}_1)}{\hat{\theta}_2^2}\\
    \frac{\delta \ln L(x_1,\dots,\ x_n,\ \theta)}{\delta \theta_2} = -\frac{n}{\hat{\theta}_2} + \frac{\sion (x_i - \hat{\theta}_1)^2}{\hat{\theta_2}^3}
\end{cases}\]
Посчитаем $\theta_1,\ \theta_2$:
\[\begin{cases}
    \sion (x_i - \hat{\theta}_1) = 0 \Rightarrow \hat{\theta}_1 = \frac{1}{n} \sion x_i = \overline{X}\\
    -n\hat{\theta}_2^2 + \sion (x_i - \overline{x})^2 = 0 \Rightarrow \hat{\theta}_2^2 = \frac{1}{n} \sion (x_i - \overline{x})^2
\end{cases}\]
\end{document}
